{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "# For deep learning\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# For augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Own package imports\n",
    "os.chdir('/home/naro/projects/Rumex')\n",
    "\n",
    "from config.paths_config import *\n",
    "from config.config import *\n",
    "from data.data_inspection import *\n",
    "from data.augmentation import *\n",
    "from data.dataset import *\n",
    "from utils.viz_utils import *\n",
    "from utils.data_utils import *\n",
    "from models.model_factory import *\n",
    "from scripts.evaluate import *\n",
    "from scripts.train import *\n",
    "from scripts.inference import predict_and_visualize_image, load_best_model\n",
    "from utils.fiftyone_utils import *\n",
    "from tuning.hyperparameters_tuning import *\n",
    "\n",
    "VIZ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PathsConfig\n",
    "pathconfig ={\n",
    "    \"dataset_name\": \"haldennord09\",\n",
    "    \"darwin_root\": \"/home/naro/.darwin/datasets/digital-production\",\n",
    "    \"dataset_version\": \"latest\",\n",
    "    \"extension\": 'png',\n",
    "    \"models_dir\": '/home/naro/projects/Rumex/artifacts/models'\n",
    "} \n",
    "\n",
    "paths_config = PathsConfig(**pathconfig)\n",
    "\n",
    "# Initialize DataVerifier\n",
    "data_verifier = DataVerifier(\n",
    "    img_dir=paths_config.img_dir,\n",
    "    annotations_dir=paths_config.annotations_dir,\n",
    "    train_split_file=paths_config.train_split_file,\n",
    "    test_split_file=paths_config.test_split_file,\n",
    "    val_split_file=paths_config.val_split_file,\n",
    "    extension=paths_config.extension\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "train_annotations, test_annotations, val_annotations = data_verifier.check_directory_contents()\n",
    "\n",
    "# Initialize ImageProcessor\n",
    "image_processor = ImagesClassesInspector(\n",
    "    img_dir=paths_config.img_dir,\n",
    "    annotations_dir=paths_config.annotations_dir\n",
    ")\n",
    "\n",
    "# Get image and annotation lists\n",
    "train_images = data_verifier.get_image_files(train_annotations)\n",
    "val_images = data_verifier.get_image_files(val_annotations)\n",
    "test_images = data_verifier.get_image_files(test_annotations)\n",
    "\n",
    "# Get image sizes\n",
    "image_files = os.listdir(paths_config.img_dir)\n",
    "train_sizes = image_processor.get_image_sizes(image_files)\n",
    "\n",
    "# Get classes\n",
    "annotation_files = train_annotations + test_annotations + val_annotations\n",
    "classes = image_processor.get_classes(annotation_files)\n",
    "print(\"\\nClasses in the dataset:\")\n",
    "print(classes)\n",
    "\n",
    "class_map = {name: idx + 1 for idx, name in enumerate(classes)}\n",
    "print(\"\\nThe created class map:\")\n",
    "print(class_map)\n",
    "\n",
    "# Get image size stats\n",
    "min_size, max_size = image_processor.get_image_size_stats(image_files)\n",
    "print(f\"Smallest image size: {min_size}\")\n",
    "print(f\"Largest image size: {max_size}\")\n",
    "\n",
    "w_min, h_min = min_size\n",
    "print(f\"Width of smallest image: {w_min}\")\n",
    "print(f\"Height of smallest image: {h_min}\")\n",
    "\n",
    "# Initialize AugmentationConfig\n",
    "augmentation_config = AugmentationConfig(height=h_min, width=w_min)\n",
    "\n",
    "# Get transforms\n",
    "train_transform = augmentation_config.get_train_transform()\n",
    "valid_transform = augmentation_config.get_valid_transform()\n",
    "\n",
    "# Print transform configurations\n",
    "print(\"Training transforms:\")\n",
    "print(train_transform)\n",
    "print(\"\\nValidation transforms:\")\n",
    "print(valid_transform)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    img_dir=paths_config.img_dir,\n",
    "    annotation_dir=paths_config.annotations_dir,\n",
    "    train_images=train_images,\n",
    "    train_annotations=train_annotations,\n",
    "    val_images=val_images,\n",
    "    val_annotations=val_annotations,\n",
    "    test_images=test_images,\n",
    "    test_annotations=test_annotations,\n",
    "    train_transform=train_transform,\n",
    "    valid_transform=valid_transform,\n",
    "    class_map=class_map\n",
    ")\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(f\"Number of samples in training dataset: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of samples in validation dataset: {len(val_loader.dataset)}\")\n",
    "print(f\"Number of samples in test dataset: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define number of classes (update this for your dataset)\n",
    "num_classes = 2  # e.g., background + bird\n",
    "\n",
    "# Initialize a Faster R-CNN model with ResNet50 backbone\n",
    "model_config = {\n",
    "    'model_name': 'fasterrcnn',\n",
    "    'backbone_name': 'resnet50',\n",
    "    'num_classes': num_classes,\n",
    "    'device': device,\n",
    "    'weights': 'COCO_V1',\n",
    "    'train_backbone': False\n",
    "}\n",
    "\n",
    "model = init_model(**model_config)\n",
    "\n",
    "model_path = \"/home/naro/projects/Rumex/mlruns/260316289658278492/b6c988fecd6b4b6898a199a1064a1b3b/artifacts/model/data/model.pth\"  # Update with your model path\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate it using the map50 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a new evaluation function here, then deploy it to the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rumex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
