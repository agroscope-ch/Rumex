{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b25e7a-2cef-44f1-9e7e-b8206a998295",
   "metadata": {},
   "source": [
    "This code extracts 10 small image patches randomly from each dataset and saves them locally to make it easier for visualise the overlay of these images together with the PCA from the embeddings (because albumentations and lightly do not work well together because of the pydantic version).\n",
    "\n",
    "The image patches are extracted where there are rumex plants, but for simplicity the bounding boxes are not overlayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803d888-bc6d-40bb-a62a-13451c01f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "darwin_path = (\n",
    "    \"/mnt/Data-Work-RE/26_Agricultural_Engineering-RE/263_DP/00_Darwin/digital-production\"\n",
    ")\n",
    "df = pd.read_csv('../assets/lightly_totalimages_selectedimages_annotated_with_fields_label.csv')\n",
    "im_dir = os.path.join(darwin_path, 'lightly/images')\n",
    "ann_dir = os.path.join(darwin_path, 'lightly/releases/1/annotations')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6628b-3dc8-4aac-93c9-f52bf2763d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_crops_per_dataset(df, im_dir, ann_dir, crop_height=1000, crop_width=1000, output_dir='./figures/patches'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Albumentations crop transform\n",
    "    transform = A.Compose([\n",
    "        A.AtLeastOneBBoxRandomCrop(height=crop_height, width=crop_width, p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing datasets\"):\n",
    "        dataset = row['dataset']\n",
    "\n",
    "        # Find all image paths for this dataset\n",
    "        img_paths = glob(os.path.join(im_dir, f\"{dataset}*.jpg\")) + glob(os.path.join(im_dir, f\"{dataset}*.png\"))\n",
    "        if len(img_paths) < 1:\n",
    "            print(f\"No images found for dataset: {dataset}\")\n",
    "            continue\n",
    "\n",
    "        # Select 10 random images (or fewer if not available)\n",
    "        selected_imgs = random.sample(img_paths, min(10, len(img_paths)))\n",
    "\n",
    "        for crop_idx, img_path in enumerate(selected_imgs):\n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Failed to load image: {img_path}\")\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Load corresponding annotation\n",
    "            basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            ann_path = os.path.join(ann_dir, f\"{basename}.json\")\n",
    "            if not os.path.exists(ann_path):\n",
    "                print(f\"Annotation not found for image: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            with open(ann_path, 'r') as f:\n",
    "                ann = json.load(f)\n",
    "\n",
    "            # Extract bboxes\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            for annotation in ann.get('annotations', []):\n",
    "                if 'bounding_box' not in annotation:\n",
    "                    continue\n",
    "                bbox = annotation['bounding_box']\n",
    "                x_min = bbox['x']\n",
    "                y_min = bbox['y']\n",
    "                x_max = x_min + bbox['w']\n",
    "                y_max = y_min + bbox['h']\n",
    "                if annotation.get('name', 'object') == 'rumex_plant':\n",
    "                    bboxes.append([x_min, y_min, x_max, y_max])\n",
    "                    labels.append(annotation.get('name', 'object'))\n",
    "\n",
    "            if not bboxes:\n",
    "                continue\n",
    "\n",
    "            # Apply crop\n",
    "            try:\n",
    "                transformed = transform(image=image, bboxes=bboxes, class_labels=labels)\n",
    "            except Exception as e:\n",
    "                print(f\"Transform failed for {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            cropped_img = transformed['image']\n",
    "\n",
    "            # Save cropped image\n",
    "            original_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            save_path = os.path.join(output_dir, f\"{original_name}-CROP{crop_idx+1}.jpg\")\n",
    "            cropped_img_bgr = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(save_path, cropped_img_bgr)\n",
    "\n",
    "    print(f\"All crops saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44980b31-1c98-4e34-ba93-e210fddb4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets: 100%|██████████| 50/50 [04:05<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All crops saved in ./figures/patches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "save_sample_crops_per_dataset(df, im_dir, ann_dir, crop_height=678, crop_width=678, output_dir='./figures/patches')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer Vision Default",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
