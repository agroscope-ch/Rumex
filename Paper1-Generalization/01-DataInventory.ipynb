{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_path = '/darwin/digital-production'\n",
    "datasets = os.listdir(darwin_path)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pixel_count_simple(image_path):\n",
    "    \"\"\"Return just the total pixel count of an image.\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        return width * height\n",
    "    \n",
    "\n",
    "def get_dataset_dimensions(dataset_path):\n",
    "    \"\"\"\n",
    "    Extract all lengths, widths, and areas from all annotation files in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset directory containing JSON annotation files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing lists of heights, widths, and areas\n",
    "    \"\"\"\n",
    "    heights = []\n",
    "    widths = []\n",
    "    areas = []\n",
    "    \n",
    "    # Get all JSON files in the dataset directory\n",
    "    dataset_dir = Path(dataset_path)\n",
    "    json_files = list(dataset_dir.glob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {dataset_path}\")\n",
    "        return {\n",
    "            'heights': heights,\n",
    "            'widths': widths,\n",
    "            'areas': areas,\n",
    "            'total_annotations': 0,\n",
    "            'total_files': 0\n",
    "        }\n",
    "    \n",
    "    total_annotations = 0\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            annotations = data.get('annotations', [])\n",
    "            \n",
    "            for annotation in annotations:\n",
    "                if 'bounding_box' in annotation:\n",
    "                    bbox = annotation['bounding_box']\n",
    "                    h = bbox['h']\n",
    "                    w = bbox['w']\n",
    "                    area = h * w\n",
    "                    \n",
    "                    heights.append(h)\n",
    "                    widths.append(w)\n",
    "                    areas.append(area)\n",
    "                    total_annotations += 1\n",
    "                    \n",
    "        except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'heights': heights,\n",
    "        'widths': widths,\n",
    "        'areas': areas,\n",
    "        'total_annotations': total_annotations,\n",
    "        'total_files': len(json_files)\n",
    "    }\n",
    "\n",
    "def get_dimensions_from_file_list(json_files):\n",
    "    \"\"\"\n",
    "    Extract dimensions from a specific list of JSON annotation files.\n",
    "    \n",
    "    Args:\n",
    "        json_files (list): List of paths to JSON annotation files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing lists of heights, widths, and areas\n",
    "    \"\"\"\n",
    "    heights = []\n",
    "    widths = []\n",
    "    areas = []\n",
    "    total_annotations = 0\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            annotations = data.get('annotations', [])\n",
    "            \n",
    "            for annotation in annotations:\n",
    "                if 'bounding_box' in annotation:\n",
    "                    bbox = annotation['bounding_box']\n",
    "                    h = bbox['h']\n",
    "                    w = bbox['w']\n",
    "                    area = h * w\n",
    "                    \n",
    "                    heights.append(h)\n",
    "                    widths.append(w)\n",
    "                    areas.append(area)\n",
    "                    total_annotations += 1\n",
    "                    \n",
    "        except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'heights': heights,\n",
    "        'widths': widths,\n",
    "        'areas': areas,\n",
    "        'total_annotations': total_annotations,\n",
    "        'total_files': len(json_files)\n",
    "    }\n",
    "\n",
    "def get_dimensions_from_single_file(json_file_path):\n",
    "    \"\"\"\n",
    "    Extract dimensions from a single JSON annotation file.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to a single JSON annotation file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing lists of heights, widths, and areas\n",
    "    \"\"\"\n",
    "    heights = []\n",
    "    widths = []\n",
    "    areas = []\n",
    "    \n",
    "    try:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        annotations = data.get('annotations', [])\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            if 'bounding_box' in annotation:\n",
    "                bbox = annotation['bounding_box']\n",
    "                h = bbox['h']\n",
    "                w = bbox['w']\n",
    "                area = h * w\n",
    "                \n",
    "                heights.append(h)\n",
    "                widths.append(w)\n",
    "                areas.append(area)\n",
    "                \n",
    "    except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "        print(f\"Error processing {json_file_path}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'heights': heights,\n",
    "        'widths': widths,\n",
    "        'areas': areas,\n",
    "        'total_annotations': len(heights)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_info = {}\n",
    "\n",
    "for d in datasets:\n",
    "        datasets_info[d] = {\n",
    "            'n_images': 0,\n",
    "            'pixel_count': 0,\n",
    "            'bboxes_count': 0,\n",
    "            'bboxes_pixel_count': 0,\n",
    "            'widths_distribution': [],\n",
    "            'areas_distribution': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "\n",
    "   # checking images count    \n",
    "    images_path = os.path.join(darwin_path, d, 'images')\n",
    "    images_list = os.listdir(images_path)\n",
    "    count = len(images_list)\n",
    "    # print(count)\n",
    "    datasets_info[d]['n_images'] = count  \n",
    "\n",
    "   # Checking the pixels count\n",
    "    pixel_count_dataset = 0\n",
    "    for image in images_list:\n",
    "        image_path = os.path.join(images_path, image)\n",
    "        pixel_count_image = get_pixel_count_simple(image_path)\n",
    "        pixel_count_dataset = pixel_count_dataset + pixel_count_image\n",
    "    # print(pixel_count_dataset)\n",
    "    datasets_info[d]['pixel_count'] = pixel_count_dataset\n",
    "\n",
    "\n",
    "    # Checking the pixels count distribution (length, widths, areas) for all annotations\n",
    "    annotations_path = os.path.join(darwin_path, d, 'releases/latest/annotations/')\n",
    "    dimensions = get_dataset_dimensions(annotations_path)\n",
    "    # print(dimensions)\n",
    "    datasets_info[d]['bboxes_count'] = dimensions['total_annotations']\n",
    "    datasets_info[d]['widths_distribution'] = dimensions['widths']\n",
    "    datasets_info[d]['areas_distribution'] = dimensions['areas']\n",
    "    bboxes_pixel_count = np.sum(dimensions['areas'])\n",
    "    datasets_info[d]['bboxes_pixel_count'] = bboxes_pixel_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in datasets_info:\n",
    "    print(f\"Dataset: {d}\")\n",
    "    print(f\"Total pixel count: {datasets_info[d]['pixel_count']}\")\n",
    "    print(f\"Number of bounding boxes: {datasets_info[d]['bboxes_count']}\")\n",
    "    print(f\"Total Pixel count in annotations: {datasets_info[d]['bboxes_pixel_count']}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets\n",
    "pixel_counts_dataset = [datasets_info[d]['pixel_count'] for d in datasets] \n",
    "pixel_counts_bboxes = [datasets_info[d]['bboxes_pixel_count'] for d in datasets]\n",
    "bboxes_counts = [datasets_info[d]['bboxes_count'] for d in datasets]\n",
    "avg_pixel_count_bboxes = [datasets_info[d]['bboxes_pixel_count'] / datasets_info[d]['bboxes_count'] for d in datasets]\n",
    "bboxes_pixels_to_image_ratio = [datasets_info[d]['bboxes_pixel_count'] / datasets_info[d]['pixel_count'] for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"gray\")  # Grayscale for some journals\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "total = 5\n",
    "# First plot\n",
    "plt.subplot(1, total, 1)  # 2 rows, 2 cols, position 1\n",
    "sns.barplot(x=datasets, y=pixel_counts_dataset)\n",
    "plt.title('Number of pixels in each \\n  dataset (all images combined)')\n",
    "plt.xticks(rotation=45)  # Tilt x-axis labels\n",
    "\n",
    "# Second plot\n",
    "plt.subplot(1, total, 2)  # 2 rows, 2 cols, position 2\n",
    "sns.barplot(x=datasets, y=bboxes_counts)\n",
    "plt.title('Number of bounding boxes \\nin each dataset')\n",
    "plt.xticks(rotation=45)  # Tilt x-axis labels\n",
    "\n",
    "# Third plot\n",
    "plt.subplot(1, total, 3)  # 2 rows, 2 cols, position 3\n",
    "sns.barplot(x=datasets, y=pixel_counts_bboxes)\n",
    "plt.title('Pixel count in bounding \\nboxes in each dataset')\n",
    "plt.xticks(rotation=45)  # Tilt x-axis labels\n",
    "\n",
    "plt.subplot(1, total, 4)  # 2 rows, 2 cols, position 3\n",
    "sns.barplot(x=datasets, y=avg_pixel_count_bboxes)\n",
    "plt.title('Average pixel count \\n per bounding box')\n",
    "plt.xticks(rotation=45)  # Tilt x-axis labels\n",
    "\n",
    "plt.subplot(1, total, 5)  # 2 rows, 2 cols, position 3\n",
    "sns.barplot(x=datasets, y=bboxes_pixels_to_image_ratio)\n",
    "plt.title('bounding boxes pixel count \\n to image pixel count ratio')\n",
    "plt.xticks(rotation=45)  # Tilt x-axis labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Setup for visualization\n",
    "fig, axes = plt.subplots(1, len(datasets), figsize=(20, 4))\n",
    "transform = A.Compose([\n",
    "    A.AtLeastOneBBoxRandomCrop(height=678, width=678, p=1.0)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "plot_idx = 0\n",
    "for d in datasets:\n",
    "    # Your existing code\n",
    "    images_path = os.path.join(darwin_path, d, 'images')\n",
    "    images_list = os.listdir(images_path)\n",
    "    count = len(images_list)\n",
    "    datasets_info[d]['n_images'] = count  \n",
    "    \n",
    "    pixel_count_dataset = 0\n",
    "    for image in images_list:\n",
    "        image_path = os.path.join(images_path, image)\n",
    "        pixel_count_image = get_pixel_count_simple(image_path)\n",
    "        pixel_count_dataset = pixel_count_dataset + pixel_count_image\n",
    "    datasets_info[d]['pixel_count'] = pixel_count_dataset\n",
    "    \n",
    "    annotations_path = os.path.join(darwin_path, d, 'releases/latest/annotations/')\n",
    "    dimensions = get_dataset_dimensions(annotations_path)\n",
    "    datasets_info[d]['bboxes_count'] = dimensions['total_annotations']\n",
    "    datasets_info[d]['widths_distribution'] = dimensions['widths']\n",
    "    datasets_info[d]['areas_distribution'] = dimensions['areas']\n",
    "    bboxes_pixel_count = np.sum(dimensions['areas'])\n",
    "    datasets_info[d]['bboxes_pixel_count'] = bboxes_pixel_count\n",
    "    \n",
    "    # Visualization code\n",
    "    json_files = [f for f in os.listdir(annotations_path) if f.endswith('.json')]\n",
    "    random_json = random.choice(json_files)\n",
    "    \n",
    "    with open(os.path.join(annotations_path, random_json), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_name = data['item']['name']\n",
    "    image_path = os.path.join(images_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Prepare bboxes for albumentations (pascal_voc format: [x_min, y_min, x_max, y_max])\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    for annotation in data.get('annotations', []):\n",
    "        bbox = annotation['bounding_box']\n",
    "        x_min = bbox['x']\n",
    "        y_min = bbox['y']\n",
    "        x_max = bbox['x'] + bbox['w']\n",
    "        y_max = bbox['y'] + bbox['h']\n",
    "        bboxes.append([x_min, y_min, x_max, y_max])\n",
    "        class_labels.append(annotation.get('name', 'object'))\n",
    "    \n",
    "    # Apply transformation with bbox adjustment\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    cropped_image = transformed['image']\n",
    "    cropped_bboxes = transformed['bboxes']\n",
    "    \n",
    "    axes[plot_idx].imshow(cropped_image)\n",
    "    axes[plot_idx].set_title(f'{d}')\n",
    "    axes[plot_idx].axis('off')\n",
    "    \n",
    "    # Draw adjusted bounding boxes\n",
    "    for bbox in cropped_bboxes:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        axes[plot_idx].add_patch(rect)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for Lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_dir = Path(os.path.join(darwin_path, 'lightly', 'releases/latest/annotations/'))\n",
    "json_files = list(dataset_dir.glob(\"*.json\"))\n",
    "datasets_names =[str(s).split('/')[-1].split('.')[0].split('_')[1] for s in json_files]   # get the name of the dataset\n",
    "datasetscounts = pd.Series(datasets_names).value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.barplot(y=datasetscounts.index, x=datasetscounts.values, order=datasetscounts.index)\n",
    "plt.title('Number of images in each dataset')\n",
    "plt.xlabel('Elements')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetscounts.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
